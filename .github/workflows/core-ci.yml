name: Core CI

on:
  push:
    branches: [main]
    paths:
      - 'core/**'
      - '.github/workflows/core-ci.yml'
  pull_request:
    branches: [main]
    paths:
      - 'core/**'
      - '.github/workflows/core-ci.yml'

env:
  MIX_ENV: test
  ELIXIR_VERSION: '1.18'
  OTP_VERSION: '27.0'

jobs:
  quality:
    name: Code Quality (Elixir ${{ matrix.elixir }} / OTP ${{ matrix.otp }})
    runs-on: ubuntu-latest

    strategy:
      matrix:
        elixir: ['1.18']
        otp: ['27.0']

    defaults:
      run:
        working-directory: core

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Elixir
        uses: erlef/setup-beam@v1
        with:
          elixir-version: ${{ matrix.elixir }}
          otp-version: ${{ matrix.otp }}

      - name: Restore dependencies cache
        uses: actions/cache@v4
        with:
          path: |
            core/deps
            core/_build
          key: ${{ runner.os }}-core-mix-${{ matrix.otp }}-${{ matrix.elixir }}-${{ hashFiles('core/mix.lock', 'mix.lock') }}
          restore-keys: |
            ${{ runner.os }}-core-mix-${{ matrix.otp }}-${{ matrix.elixir }}-

      - name: Install dependencies
        run: mix deps.get

      - name: Compile dependencies
        run: mix deps.compile

      - name: Check formatting
        run: mix format --check-formatted

      - name: Compile with warnings as errors
        run: mix compile --warnings-as-errors

      - name: Run Credo (if available)
        run: mix credo --strict || echo "Credo not configured, skipping"
        continue-on-error: true

      - name: Restore PLT cache
        uses: actions/cache@v4
        id: plt-cache
        with:
          path: core/priv/plts
          key: ${{ runner.os }}-core-plt-${{ matrix.otp }}-${{ matrix.elixir }}-${{ hashFiles('core/mix.lock', 'mix.lock') }}
          restore-keys: |
            ${{ runner.os }}-core-plt-${{ matrix.otp }}-${{ matrix.elixir }}-

      - name: Create PLTs
        if: steps.plt-cache.outputs.cache-hit != 'true'
        run: mix dialyzer --plt || echo "Dialyzer not configured, skipping"
        continue-on-error: true

      - name: Run Dialyzer
        run: mix dialyzer || echo "Dialyzer not configured, skipping"
        continue-on-error: true

  tests:
    name: Property-Based Tests (Elixir ${{ matrix.elixir }} / OTP ${{ matrix.otp }})
    runs-on: ubuntu-latest
    timeout-minutes: 60

    strategy:
      matrix:
        elixir: ['1.18']
        otp: ['27.0']

    defaults:
      run:
        working-directory: core

    env:
      # PropCheck configuration for CI - stateful GenServer tests are expensive
      PROPCHECK_NUMTESTS: 300
      PROPCHECK_VERBOSE: true
      PROPCHECK_SEARCH_STEPS: 100000
      # Use deterministic seed for reproducibility
      PROPCHECK_SEED: ${{ github.run_id }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Elixir
        uses: erlef/setup-beam@v1
        with:
          elixir-version: ${{ matrix.elixir }}
          otp-version: ${{ matrix.otp }}

      - name: Restore dependencies cache
        uses: actions/cache@v4
        with:
          path: |
            core/deps
            core/_build
          key: ${{ runner.os }}-core-mix-${{ matrix.otp }}-${{ matrix.elixir }}-${{ hashFiles('core/mix.lock', 'mix.lock') }}
          restore-keys: |
            ${{ runner.os }}-core-mix-${{ matrix.otp }}-${{ matrix.elixir }}-

      - name: Install dependencies
        run: mix deps.get

      - name: Compile
        run: mix compile --warnings-as-errors

      - name: Run all property-based tests
        run: |
          echo "======================================"
          echo "Running Property-Based Test Suite"
          echo "Configuration:"
          echo "  - Test cases per property: $PROPCHECK_NUMTESTS"
          echo "  - Search steps for shrinking: $PROPCHECK_SEARCH_STEPS"
          echo "  - Seed: $PROPCHECK_SEED"
          echo "======================================"
          echo ""

          # Run tests with coverage and capture results
          TEST_EXIT_CODE=0
          mix test --cover --trace --slowest 10 2>&1 | tee test_output.log || TEST_EXIT_CODE=$?

          echo ""
          echo "╔════════════════════════════════════════════════════════════════════╗"
          echo "║                        TEST SUMMARY REPORT                         ║"
          echo "╚════════════════════════════════════════════════════════════════════╝"
          echo ""

          # Parse test results
          if [ $TEST_EXIT_CODE -eq 0 ]; then
            TOTAL_TESTS=$(grep -oP '\d+ tests?' test_output.log | tail -1 | grep -oP '\d+' || echo "0")
            PASSED_TESTS=$TOTAL_TESTS
            FAILED_TESTS=0

            echo "┌─────────────────────────────────────┐"
            echo "│         ✅  ALL TESTS PASSED        │"
            echo "└─────────────────────────────────────┘"
            echo ""
            echo "  📊 Test Statistics:"
            echo "  ├─ Total Tests:   $TOTAL_TESTS"
            echo "  ├─ Passed:        $PASSED_TESTS ✓"
            echo "  └─ Failed:        $FAILED_TESTS"
          else
            TOTAL_TESTS=$(grep -oP '\d+ tests?' test_output.log | tail -1 | grep -oP '\d+' || echo "0")
            FAILED_TESTS=$(grep -oP '\d+ failures?' test_output.log | tail -1 | grep -oP '\d+' || echo "0")
            PASSED_TESTS=$((TOTAL_TESTS - FAILED_TESTS))

            echo "┌─────────────────────────────────────┐"
            echo "│         ❌  TESTS FAILED            │"
            echo "└─────────────────────────────────────┘"
            echo ""
            echo "  📊 Test Statistics:"
            echo "  ├─ Total Tests:   $TOTAL_TESTS"
            echo "  ├─ Passed:        $PASSED_TESTS ✓"
            echo "  └─ Failed:        $FAILED_TESTS ✗"
            echo ""
            echo "  ⚠️  Failed Tests:"
            echo "  ─────────────────"

            # Extract failed test names
            grep -A 2 "^\s*\d\+)" test_output.log | grep "test " | sed 's/^/  • /' || echo "  (Could not parse failed test names)"
          fi

          echo ""
          echo "  📈 Coverage Report:"
          echo "  ───────────────────"

          # Extract coverage info from output
          if grep -q "COV" test_output.log; then
            grep "COV" test_output.log | tail -5 | while read line; do
              echo "  $line"
            done
            echo ""
            TOTAL_COV=$(grep -oP 'Total.*?(\d+\.\d+)%' test_output.log | tail -1 | grep -oP '\d+\.\d+' || echo "N/A")
            echo "  📊 Total Coverage: $TOTAL_COV%"
          else
            echo "  (Coverage data will be generated separately)"
          fi

          echo ""
          echo "  ⏱️  Performance:"
          echo "  ────────────────"
          echo "  (See slowest tests above)"

          echo ""
          echo "  🔧 PropCheck Configuration:"
          echo "  ───────────────────────────"
          echo "  • Test cases per property: $PROPCHECK_NUMTESTS"
          echo "  • Search steps: $PROPCHECK_SEARCH_STEPS"
          echo "  • Seed: $PROPCHECK_SEED"

          echo ""
          echo "╔════════════════════════════════════════════════════════════════════╗"

          if [ $TEST_EXIT_CODE -eq 0 ]; then
            echo "║                    🎉  BUILD SUCCESSFUL  🎉                        ║"
          else
            echo "║                     💥  BUILD FAILED  💥                           ║"
          fi

          echo "╚════════════════════════════════════════════════════════════════════╝"
          echo ""

          # Exit with the original test exit code
          exit $TEST_EXIT_CODE

      - name: Upload PropCheck counterexamples
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: propcheck-counterexamples-core-${{ github.run_id }}
          path: |
            core/.propcheck
            core/counterexample.*.erl
          if-no-files-found: ignore
          retention-days: 30

      - name: Upload test reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-reports-core-${{ github.run_id }}
          path: core/_build/test/lib/ntbr_core/
          if-no-files-found: ignore
          retention-days: 7
